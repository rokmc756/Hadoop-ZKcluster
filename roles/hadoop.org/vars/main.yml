---
user: "hadoop"
group: "hadoop"

master_ip: "{{ hostvars[groups['master'][0]]['ansible_'~ netdev0]['ipv4']['address'] }}"
master_hostname: "{{ hostvars[groups['master'][0]].ansible_hostname }}"
standby_master_ip: "{{ hostvars[groups['standby'][0]]['ansible_'~ netdev0]['ipv4']['address'] }}"
standby_master_hostname: "{{ hostvars[groups['standby'][0]].ansible_hostname }}"

# download_path: "/Users/moonja/Downloads"
# download_hadoop: false
download_path: "/tmp"
hadoop_version: "{{ hadoop.major_version }}.{{ hadoop.minor_version }}.{{ hadoop.patch_version }}"
# hadoop_path: "/home/hadoop"
hadoop_config_path: "/home/hadoop/hadoop-{{hadoop_version}}/etc/hadoop"
hadoop_tmp: "/home/hadoop/tmp"
hadoop_dfs_name: "/home/hadoop/dfs/name"
hadoop_dfs_data: "/home/hadoop/dfs/data"
hadoop_log_path: "/home/hadoop/hadoop_logs"
hadoop_journalnode_path: "/home/hadoop/journalnode/data"


hadoop_create_path:
  - "{{ hadoop_tmp }}"
  - "{{ hadoop_dfs_name }}"
  - "{{ hadoop_dfs_data }}"
  - "{{ hadoop_log_path }}"
  - "{{ hadoop_journalnode_path }}"


# hadoop configration
hdfs_port: 9000
  #zkquorum_list: |
  #{% set results = [] %}
  #{% for host in groups['all'] %}
  #{{ hostvars[host][ansible_hostname] }}:2181
  #{% endfor %}
  #{% set results = [] %}


zkservers_list: "{{ groups['all'] | map('extract', hostvars, ['ansible_fqdn']) | map('regex_replace', '$', ':2181') | join(',') }}"
qjournal_list: "{{ groups['all'] | map('extract', hostvars, ['ansible_hostname']) | map('regex_replace', '$', '.jtest.pivotal.io:8485') | join(';') }}"


core_site_properties:
  - {
      "name":"fs.defaultFS",
      "value":"hdfs://{{ master_ip }}:{{ hdfs_port }}"
  }
  - {
      "name":"hadoop.tmp.dir",
      "value":"file:{{ hadoop_tmp }}"
  }
  - {
    "name":"io.file.buffer.size",
    "value":"131072"
  }
  - {
      "name":"ha.zookeeper.quorum",
      "value":"{{ zkservers_list }}"
  }
  - {
    "name":"ha.zookeeper.session-timeout.ms",
    "value":"10000"
  }
  - {
    "name":"hadoop.proxyuser.gpadmin.hosts",
    "value":"*"
  }
  - {
    "name":"hadoop.proxyuser.gpadmin.groups",
    "value":"*"
  }

# dfs_namenode_httpport: 9001
hdfs_site_properties:
  - {
      "name":"dfs.namenode.name.dir",
      "value":"file:{{ config.dfs_name }}"
  }
  - {
      "name":"dfs.namenode.data.dir",
      "value":"file:{{ config.dfs_data }}"
  }
  - {
      "name":"dfs.replication",
      "value":"{{ groups['workers']|length }}"
  }
  - {
      "name":"dfs.webhdfs.enabled",
      "value":"true"
  }
  - {
      "name":"dfs.nameservices",
      "value":"ha-cluster"
  }
  - {
      "name":"dfs.ha.namenodes.ha-cluster",
      "value":"nn1,nn2"
  }
  - {
      "name":"dfs.namenode.rpc-address.ha-cluster.nn1",
      "value":"{{ master_hostname }}:9000"
  }
  - {
      "name":"dfs.namenode.rpc-address.ha-cluster.nn2",
      "value":"{{ standby_master_hostname }}:9000"
  }
  - {
      "name":"dfs.namenode.http-address.ha-cluster.nn1",
      "value":"{{ master_hostname }}:50070"
  }
  - {
      "name":"dfs.namenode.http-address.ha-cluster.nn2",
      "value":"{{ standby_master_hostname }}:50070"
  }
  - {
      "name":"dfs.namenode.shared.edits.dir",
      "value":"qjournal://{{ qjournal_list }}/ha-cluster"
  }
  - {
      "name":"dfs.journalnode.edits.dir",
      "value":"{{ hadoop_journalnode_path }}"
  }
  - {
      "name":"dfs.ha.fencing.methods",
      "value":"sshfence"
  }
  - {
      "name":"dfs.ha.fencing.ssh.private-key-files",
      "value":"/home/hadoop/.ssh/id_rsa"
  }
  - {
    "name":"dfs.ha.fencing.ssh.connect-timeout",
    "value":"30000"
  }
  - {
      "name":"dfs.client.failover.proxy.provider.ha-cluster",
      "value":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"
  }
  - {
      "name":"dfs.ha.automatic-failover.enabled",
      "value":"true"
  }
  - {
      "name":"dfs.ha.allow.stale.reads",
      "value":"true"
  }

  # - {
  #    "name":"dfs.datanode.max.xcievers",
  #    "value":"4096"
  #}
  #- {
  #    "name":"dfs.ha.allow.stale.reads",
  #    "value":"true"
  #}
  #- {
  #    "name":"dfs.client.use.datanode.hostname",
  #    "value":"true"
  #}
  #- {
  #    "name":"dfs.datanode.use.datanode.hostname",
  #    "value":"true"
  #}
  #- {
  #    "name":"dfs.block.size",
  #    "value":"134217728"
  #}
  #- {
  #    "name":"dfs.datatnode.address",
  #    "value":"0.0.0.0:9000"
  #}  # Applied first for Hadoop 2.10.2, 9000 was in 3.4.x

mapred_site_properties:
 - {
   "name": "mapreduce.framework.name",
   "value": "yarn"
 }
 - {
   "name": "mapreduce.admin.user.env",
   "value": "HADOOP_MAPRED_HOME=$HADOOP_COMMON_HOME"
 }
 - {
   "name":"yarn.app.mapreduce.am.env",
   "value":"HADOOP_MAPRED_HOME=$HADOOP_COMMON_HOME"
 }

yarn_resourcemanager_port: 8040
yarn_resourcemanager_scheduler_port: 8030
yarn_resourcemanager_webapp_port: 8088
yarn_resourcemanager_tracker_port: 8025
yarn_resourcemanager_admin_port: 8141

yarn_site_properties:
  - {
    "name": "yarn.nodemanager.aux-services",
    "value": "mapreduce_shuffle"
  }
  - {
    "name":"yarn.log-aggregation-enable",
    "value":"true"
  }
  - {
    "name":"yarn.log-aggregation.retain-seconds",
    "value":"86400"
  }
  - {
    "name":"yarn.resourcemanager.ha.enabled",
    "value":"true"
  }
  - {
    "name":"yarn.resourcemanager.cluster-id",
    "value":"my-yarn-cluster"
  }
  - {
    "name":"yarn.resourcemanager.ha.rm-ids",
    "value":"rm1,rm2,rm3"
  }
  - {
    "name":"yarn.resourcemanager.hostname.rm1",
    "value":"{{ hostvars[groups['workers'][0]].ansible_hostname }}"
  }
  - {
    "name":"yarn.resourcemanager.hostname.rm2",
    "value":"{{ hostvars[groups['workers'][1]].ansible_hostname }}"
  }
  - {
    "name":"yarn.resourcemanager.hostname.rm3",
    "value":"{{ hostvars[groups['workers'][2]].ansible_hostname }}"
  }
  - {
    "name":"yarn.resourcemanager.webapp.address.rm1",
    "value":"{{ hostvars[groups['workers'][0]].ansible_hostname }}:8088"
  }
  - {
    "name":"yarn.resourcemanager.webapp.address.rm2",
    "value":"{{ hostvars[groups['workers'][1]].ansible_hostname }}:8088"
  }
  - {
    "name":"yarn.resourcemanager.webapp.address.rm3",
    "value":"{{ hostvars[groups['workers'][2]].ansible_hostname }}:8088"
  }
  - {
    "name":"yarn.resourcemanager.zk-address",
    "value":"{{ zkservers_list }}"
  }
  - {
    "name":"yarn.resourcemanager.recovery.enabled",
    "value":"true"
  }
  - {
    "name":"yarn.resourcemanager.store.class",
    "value":"org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore"
  }   ###
  - {
    "name":"yarn.resourcemanager.address",
    "value":"{{ master_hostname }}:{{ yarn_resourcemanager_port }}"
  }
  - {
    "name":"yarn.resourcemanager.scheduler.address",
    "value":"{{ master_hostname }}:{{ yarn_resourcemanager_scheduler_port }}"
  }
  - {
    "name":"yarn.resourcemanager.webapp.address",
    "value":"{{ master_hostname }}:{{ yarn_resourcemanager_webapp_port }}"
  }
  - {
    "name": "yarn.resourcemanager.resource-tracker.address",
    "value": "{{ master_hostname }}:{{ yarn_resourcemanager_tracker_port }}"
  }
  - {
    "name": "yarn.resourcemanager.admin.address",
    "value": "{{ master_hostname }}:{{ yarn_resourcemanager_admin_port }}"
  }
  - {
    "name": "yarn.nodemanager.aux-services.mapreduce.shuffle.class",
    "value": "org.apache.hadoop.mapred.ShuffleHandler"
  }


#dashbord_port: 9870
#firewall_ports:
#  - "{{ dashbord_port}}"
#  - "{{ hdfs_port }}"
#  - "{{ dfs_namenode_httpport }}"
#  - "{{ yarn_resourcemanager_port }}"
#  - "{{ yarn_resourcemanager_scheduler_port }}"
#  - "{{ yarn_resourcemanager_webapp_port }}"
#  - "{{ yarn_resourcemanager_tracker_port }}"
#  - "{{ yarn_resourcemanager_admin_port }}"
#  - "8485"
#  - "50010"


